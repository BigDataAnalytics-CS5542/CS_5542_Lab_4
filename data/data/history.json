{
  "default_user": [
    {
      "question": "How does rag work?",
      "top_k": 5,
      "retrieval_mode": "hybrid",
      "use_multimodal": true,
      "alpha": 0.6,
      "timestamp": 1770955298.29685,
      "latency_ms": 1791.4800643920898,
      "evidence": [
        {
          "evidence_id": "gfm_rag_p07_c001",
          "hybrid_score": 0.791021858814533,
          "bm25_norm": 1.0,
          "dense_norm": 0.6517030980242215,
          "source_file": "gfm_rag.pdf",
          "page": 7,
          "text": "4 Experiment In experiments, we aim to address the following research questions: (1) How doesGFM-RAG perform in multi-hop retrieval and QA tasks? (Sections 4.2 and 4.3); (2) What are the efficiency and effectiveness of GFM-RAG in multi-hop retrieval? (Section 4.4); (3) How well does GFM-RAG generalize to unseen datasets as a foundation model? (Section 4.6); (4) How does the performance of GFM-RAG scale with training as a foundation model? (Section 4.7); (5) How to interpret GFM-RAG in multi-hop reasoning? (Section 4.8). 4.1 Experimental Setup Datasets. We first evaluate the effectiveness ofGFM",
          "citation": "(gfm_rag.pdf p7, chunk 1)"
        },
        {
          "evidence_id": "img_gfm_rag_framework",
          "hybrid_score": 0.6,
          "bm25_norm": 0.0,
          "dense_norm": 1.0,
          "source_file": "gfm_rag_framework.png",
          "page": 0,
          "text": "gfm rag framework",
          "citation": "(image: gfm_rag_framework.png)"
        },
        {
          "evidence_id": "img_gfm_rag_results_table",
          "hybrid_score": 0.4674227552826091,
          "bm25_norm": 0.0,
          "dense_norm": 0.7790379254710152,
          "source_file": "gfm_rag_results_table.png",
          "page": 0,
          "text": "gfm rag results table",
          "citation": "(image: gfm_rag_results_table.png)"
        },
        {
          "evidence_id": "rag_evaluation_benchmark_p01_c002",
          "hybrid_score": 0.3958292744486547,
          "bm25_norm": 0.5624040306524851,
          "dense_norm": 0.2847794369794344,
          "source_file": "rag_evaluation_benchmark.pdf",
          "page": 1,
          "text": "to 81.0% reduction in cheatability scores. More broadly, our pipeline offers a simple way to enhance benchmark difficulty and realism and drive development of more capable RAG systems. Keywords:multi-hop QA\u00b7unanswerability evaluation\u00b7synthetic data 1 Introduction Retrieval Augmented Generation (RAG) [11, 23] is a powerful approach for many NLP tasks, enabling LLMs to respond to diverse user requests by leveraging an external document collection. While RAG is highly effective at increasing model credibility [15], mitigating hallucinations, and improving response quality [12], there remains a ne",
          "citation": "(rag_evaluation_benchmark.pdf p1, chunk 2)"
        },
        {
          "evidence_id": "img_ragas_table1_metrics",
          "hybrid_score": 0.36378542065230995,
          "bm25_norm": 0.0,
          "dense_norm": 0.6063090344205166,
          "source_file": "ragas_table1_metrics.png",
          "page": 0,
          "text": "ragas table1 metrics",
          "citation": "(image: ragas_table1_metrics.png)"
        }
      ],
      "text_evidence": [
        {
          "evidence_id": "gfm_rag_p07_c001",
          "hybrid_score": 0.791021858814533,
          "bm25_norm": 1.0,
          "dense_norm": 0.6517030980242215,
          "source_file": "gfm_rag.pdf",
          "page": 7,
          "text": "4 Experiment In experiments, we aim to address the following research questions: (1) How doesGFM-RAG perform in multi-hop retrieval and QA tasks? (Sections 4.2 and 4.3); (2) What are the efficiency and effectiveness of GFM-RAG in multi-hop retrieval? (Section 4.4); (3) How well does GFM-RAG generalize to unseen datasets as a foundation model? (Section 4.6); (4) How does the performance of GFM-RAG scale with training as a foundation model? (Section 4.7); (5) How to interpret GFM-RAG in multi-hop reasoning? (Section 4.8). 4.1 Experimental Setup Datasets. We first evaluate the effectiveness ofGFM",
          "citation": "(gfm_rag.pdf p7, chunk 1)"
        },
        {
          "evidence_id": "rag_evaluation_benchmark_p01_c002",
          "hybrid_score": 0.3958292744486547,
          "bm25_norm": 0.5624040306524851,
          "dense_norm": 0.2847794369794344,
          "source_file": "rag_evaluation_benchmark.pdf",
          "page": 1,
          "text": "to 81.0% reduction in cheatability scores. More broadly, our pipeline offers a simple way to enhance benchmark difficulty and realism and drive development of more capable RAG systems. Keywords:multi-hop QA\u00b7unanswerability evaluation\u00b7synthetic data 1 Introduction Retrieval Augmented Generation (RAG) [11, 23] is a powerful approach for many NLP tasks, enabling LLMs to respond to diverse user requests by leveraging an external document collection. While RAG is highly effective at increasing model credibility [15], mitigating hallucinations, and improving response quality [12], there remains a ne",
          "citation": "(rag_evaluation_benchmark.pdf p1, chunk 2)"
        }
      ],
      "image_evidence": [
        {
          "evidence_id": "img_gfm_rag_framework",
          "hybrid_score": 0.6,
          "bm25_norm": 0.0,
          "dense_norm": 1.0,
          "source_file": "gfm_rag_framework.png",
          "page": 0,
          "text": "gfm rag framework",
          "citation": "(image: gfm_rag_framework.png)"
        },
        {
          "evidence_id": "img_gfm_rag_results_table",
          "hybrid_score": 0.4674227552826091,
          "bm25_norm": 0.0,
          "dense_norm": 0.7790379254710152,
          "source_file": "gfm_rag_results_table.png",
          "page": 0,
          "text": "gfm rag results table",
          "citation": "(image: gfm_rag_results_table.png)"
        },
        {
          "evidence_id": "img_ragas_table1_metrics",
          "hybrid_score": 0.36378542065230995,
          "bm25_norm": 0.0,
          "dense_norm": 0.6063090344205166,
          "source_file": "ragas_table1_metrics.png",
          "page": 0,
          "text": "ragas table1 metrics",
          "citation": "(image: ragas_table1_metrics.png)"
        }
      ],
      "missing_evidence_behavior": false,
      "support_gate_pass": true,
      "faithfulness_pass": true,
      "answer": "4 Experiment In experiments, we aim to address the following research questions: (1) How doesGFM-RAG perform in multi-hop retrieval and QA tasks? (Sections 4.2 and 4.3); (2) What are the efficiency and effectiveness of GFM-RAG in multi-hop retrieval? (Section 4.4); (3) How well does GFM-RAG generalize to unseen datasets as a foundation model? (Section 4.6); (4) How does the performance of GFM-RAG scale with training as a foundation model? (Section 4.7); (5) How to interpret GFM-RAG in multi-hop reasoning? (Section 4.8). 4.1 Experimental Setup Datasets. We first evaluate the effectiveness ofGFM"
    }
  ]
}