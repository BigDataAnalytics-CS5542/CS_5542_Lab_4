{
  "default_user": [
    {
      "question": "Explain bm25 normalization",
      "top_k": 5,
      "retrieval_mode": "Hybrid",
      "use_multimodal": true,
      "alpha": 0.6,
      "p_at_5": null,
      "r_at_10": null,
      "timestamp": 1770959864.3727038,
      "latency_ms": 4022.99427986145,
      "evidence": [
        {
          "evidence_id": "bm25_prf_p27_c001",
          "hybrid_score": 0.9389079078592424,
          "bm25_norm": 0.847269769648106,
          "dense_norm": 1.0,
          "source_file": "bm25_prf.pdf",
          "page": 27,
          "text": "3.4 The Eliteness Model and BM25 357 3.4.4 BM25 Precursor We investigate the shape of the saturation function a little more closely. It is clear that the properties listed above severely limit the possible functions; nevertheless, there remain many possibilities, as illustrated for example in the left-hand graph in Figure 3.2. However, the 2-Poisson model generates much smoother functions, as shown in the right-hand graph. For most realistic combinations of the parameters the curve is convex, as the top two lines; for some combinations it has an initial concavity, as the bottom line. The next ",
          "citation": "(bm25_prf.pdf p27, chunk 1)"
        },
        {
          "evidence_id": "bm25_prf_p31_c001",
          "hybrid_score": 0.8620176997861977,
          "bm25_norm": 0.7677777237998076,
          "dense_norm": 0.9248443504437911,
          "source_file": "bm25_prf.pdf",
          "page": 31,
          "text": "3.6 Multiple Streams and BM25F 361 circumstances. However, there is also evidence that optimal values do depend on other factors (such as the type of documents or queries). 3.5.1 Some V ariations on BM25 Published versions of BM25 can vary somewhat (the original BM25 [46] was a little more complicated than that of Equation (3.15), for example). Here we indicate some di\ufb00erences that might be encountered in di\ufb00erent versions of the function in published sources. \u2022 The original had a component for within-query term fre- quency qtf , for longer queries where a term might occur mul- tiple times. In",
          "citation": "(bm25_prf.pdf p31, chunk 1)"
        },
        {
          "evidence_id": "img_bm25_prf_table3_1",
          "hybrid_score": 0.8472653351338238,
          "bm25_norm": 0.8792210483831381,
          "dense_norm": 0.8259615263009478,
          "source_file": "bm25_prf_table3_1.png",
          "page": 0,
          "text": "bm25 prf table3 1",
          "citation": "(image: bm25_prf_table3_1.png)"
        },
        {
          "evidence_id": "bm25_prf_p39_c002",
          "hybrid_score": 0.8137411662060561,
          "bm25_norm": 1.0,
          "dense_norm": 0.6895686103434268,
          "source_file": "bm25_prf.pdf",
          "page": 39,
          "text": "the user would unconsciouslycorrect the query by adding terms to it that disambiguate it. This does not mean that all queries and documents are position-proof, but the fraction that require positions is small. Second, it should be noted that taking into account the structure of a document (e.g., in BM25F) implicitly rewards prox- imity within important short streams, such as the title. 3.9 Open Source Implementations of BM25 and BM25F We review here several implementations of BM25 and BM25F available as open source. This list is not exhaustive, there may be other search engines or extensions o",
          "citation": "(bm25_prf.pdf p39, chunk 2)"
        },
        {
          "evidence_id": "bm25_prf_p51_c002",
          "hybrid_score": 0.7799474196700571,
          "bm25_norm": 0.7227745012675117,
          "dense_norm": 0.8180626986050873,
          "source_file": "bm25_prf.pdf",
          "page": 51,
          "text": "is because the stream weights in e\ufb00ect rescale the tf values, and k 1 has to be adjusted accordingly. If we have a goodkBM25 1 value for the regular BM25 function (no streams), we can propose a good initial value ofk1 for BM25F by scaling it according to the change Fig. 5.2 Greedy optimisation example: promising directions.",
          "citation": "(bm25_prf.pdf p51, chunk 2)"
        }
      ],
      "text_evidence": [
        {
          "evidence_id": "bm25_prf_p27_c001",
          "hybrid_score": 0.9389079078592424,
          "bm25_norm": 0.847269769648106,
          "dense_norm": 1.0,
          "source_file": "bm25_prf.pdf",
          "page": 27,
          "text": "3.4 The Eliteness Model and BM25 357 3.4.4 BM25 Precursor We investigate the shape of the saturation function a little more closely. It is clear that the properties listed above severely limit the possible functions; nevertheless, there remain many possibilities, as illustrated for example in the left-hand graph in Figure 3.2. However, the 2-Poisson model generates much smoother functions, as shown in the right-hand graph. For most realistic combinations of the parameters the curve is convex, as the top two lines; for some combinations it has an initial concavity, as the bottom line. The next ",
          "citation": "(bm25_prf.pdf p27, chunk 1)"
        },
        {
          "evidence_id": "bm25_prf_p31_c001",
          "hybrid_score": 0.8620176997861977,
          "bm25_norm": 0.7677777237998076,
          "dense_norm": 0.9248443504437911,
          "source_file": "bm25_prf.pdf",
          "page": 31,
          "text": "3.6 Multiple Streams and BM25F 361 circumstances. However, there is also evidence that optimal values do depend on other factors (such as the type of documents or queries). 3.5.1 Some V ariations on BM25 Published versions of BM25 can vary somewhat (the original BM25 [46] was a little more complicated than that of Equation (3.15), for example). Here we indicate some di\ufb00erences that might be encountered in di\ufb00erent versions of the function in published sources. \u2022 The original had a component for within-query term fre- quency qtf , for longer queries where a term might occur mul- tiple times. In",
          "citation": "(bm25_prf.pdf p31, chunk 1)"
        },
        {
          "evidence_id": "bm25_prf_p39_c002",
          "hybrid_score": 0.8137411662060561,
          "bm25_norm": 1.0,
          "dense_norm": 0.6895686103434268,
          "source_file": "bm25_prf.pdf",
          "page": 39,
          "text": "the user would unconsciouslycorrect the query by adding terms to it that disambiguate it. This does not mean that all queries and documents are position-proof, but the fraction that require positions is small. Second, it should be noted that taking into account the structure of a document (e.g., in BM25F) implicitly rewards prox- imity within important short streams, such as the title. 3.9 Open Source Implementations of BM25 and BM25F We review here several implementations of BM25 and BM25F available as open source. This list is not exhaustive, there may be other search engines or extensions o",
          "citation": "(bm25_prf.pdf p39, chunk 2)"
        },
        {
          "evidence_id": "bm25_prf_p51_c002",
          "hybrid_score": 0.7799474196700571,
          "bm25_norm": 0.7227745012675117,
          "dense_norm": 0.8180626986050873,
          "source_file": "bm25_prf.pdf",
          "page": 51,
          "text": "is because the stream weights in e\ufb00ect rescale the tf values, and k 1 has to be adjusted accordingly. If we have a goodkBM25 1 value for the regular BM25 function (no streams), we can propose a good initial value ofk1 for BM25F by scaling it according to the change Fig. 5.2 Greedy optimisation example: promising directions.",
          "citation": "(bm25_prf.pdf p51, chunk 2)"
        }
      ],
      "image_evidence": [
        {
          "evidence_id": "img_bm25_prf_table3_1",
          "hybrid_score": 0.8472653351338238,
          "bm25_norm": 0.8792210483831381,
          "dense_norm": 0.8259615263009478,
          "source_file": "bm25_prf_table3_1.png",
          "page": 0,
          "text": "bm25 prf table3 1",
          "citation": "(image: bm25_prf_table3_1.png)"
        }
      ],
      "missing_evidence_behavior": true,
      "support_gate_pass": false,
      "faithfulness_pass": false,
      "answer": "Not enough evidence in the retrieved context."
    },
    {
      "question": "How do graphs relate to RAG?",
      "top_k": 5,
      "retrieval_mode": "Hybrid",
      "use_multimodal": true,
      "alpha": 0.6,
      "p_at_5": null,
      "r_at_10": null,
      "timestamp": 1770959998.7819374,
      "latency_ms": 115.97990989685059,
      "evidence": [
        {
          "evidence_id": "graphflow_rag_p28_c001",
          "hybrid_score": 0.6,
          "bm25_norm": 0.0,
          "dense_norm": 1.0,
          "source_file": "graphflow_rag.pdf",
          "page": 28,
          "text": "(a). Generalization Results without Rerank. (b). Generalization Results with Rerank. Figure 6: Generalization Performance (Hit@5) of KG-based RAG methods. GraphFlow shows superior cross-domain generalization performance, especially under the rerank setting (best viewed in color). Figure 7: GraphFlow shows improved retrieval diversity on different difficulty levels of retrieval queries on STaRK-PRIME. E More results of Hard Cases We categorize the retrieval queries with different numbers of retrieval targets into 4 difficulty levels. We provide the performance of different KG-based RAG on STaRK",
          "citation": "(graphflow_rag.pdf p28, chunk 1)"
        },
        {
          "evidence_id": "gfm_rag_p03_c002",
          "hybrid_score": 0.5339090177164554,
          "bm25_norm": 1.0,
          "dense_norm": 0.22318169619409226,
          "source_file": "gfm_rag.pdf",
          "page": 3,
          "text": "16] enhances multi-hop retrieval by using a personalized PageRank algorithm to locate relevant knowledge with graphs. However, the graph structure can be noisy and incomplete, leading to suboptimal performance. Efforts to incorporate GNNs into graph-enhanced RAG [41, 18] have shown impressive results due to the multi-hop graph reasoning capabilities of GNNs in handling incomplete graphs [73]. Nonetheless, these methods still limit in generalizability due to the lack of a graph foundational model. Graph Foundation models (GFM) aims to be a large-scale model that can generalize to various datase",
          "citation": "(gfm_rag.pdf p3, chunk 2)"
        },
        {
          "evidence_id": "img_graphflow_rag_p04_architecture",
          "hybrid_score": 0.4468854021719025,
          "bm25_norm": 0.0,
          "dense_norm": 0.7448090036198375,
          "source_file": "graphflow_rag_p04_architecture.png",
          "page": 0,
          "text": "graphflow rag p04 architecture",
          "citation": "(image: graphflow_rag_p04_architecture.png)"
        },
        {
          "evidence_id": "gfm_rag_p27_c001",
          "hybrid_score": 0.4356642385178442,
          "bm25_norm": 0.0,
          "dense_norm": 0.726107064196407,
          "source_file": "gfm_rag.pdf",
          "page": 27,
          "text": "Table 21: Comparison of the model performance under the KG-index constructed by different LLMs. Method HotpotQA MuSiQue 2Wiki R@2 R@5 R@2 R@5 R@2 R@5 GFM-RAG (gpt-4o-mini) 78.3 87.1 49.1 58.2 90.8 95.6 HippoRAG (gpt-4o-mini) 62.2 79.3 41.7 53.6 72.1 89.5 GFM-RAG (gpt-3.5-trubo) 75.6 84.7 46.1 55.8 85.2 90.4 HippoRAG (gpt-3.5-trubo) 60.5 77.7 40.9 51.9 70.7 89.1 of GFM-RAG is significantly higher than HippoRAG under both KG-indexes. This indicates that GFM-RAG is more robust to the quality of the KG-index, demonstrating the effectiveness of the GFM in graph reasoning and retrieval. F Prompts In",
          "citation": "(gfm_rag.pdf p27, chunk 1)"
        },
        {
          "evidence_id": "img_graphflow_rag_p25_training_dynamics",
          "hybrid_score": 0.3494434394314893,
          "bm25_norm": 0.0,
          "dense_norm": 0.5824057323858155,
          "source_file": "graphflow_rag_p25_training_dynamics.png",
          "page": 0,
          "text": "graphflow rag p25 training dynamics",
          "citation": "(image: graphflow_rag_p25_training_dynamics.png)"
        }
      ],
      "text_evidence": [
        {
          "evidence_id": "graphflow_rag_p28_c001",
          "hybrid_score": 0.6,
          "bm25_norm": 0.0,
          "dense_norm": 1.0,
          "source_file": "graphflow_rag.pdf",
          "page": 28,
          "text": "(a). Generalization Results without Rerank. (b). Generalization Results with Rerank. Figure 6: Generalization Performance (Hit@5) of KG-based RAG methods. GraphFlow shows superior cross-domain generalization performance, especially under the rerank setting (best viewed in color). Figure 7: GraphFlow shows improved retrieval diversity on different difficulty levels of retrieval queries on STaRK-PRIME. E More results of Hard Cases We categorize the retrieval queries with different numbers of retrieval targets into 4 difficulty levels. We provide the performance of different KG-based RAG on STaRK",
          "citation": "(graphflow_rag.pdf p28, chunk 1)"
        },
        {
          "evidence_id": "gfm_rag_p03_c002",
          "hybrid_score": 0.5339090177164554,
          "bm25_norm": 1.0,
          "dense_norm": 0.22318169619409226,
          "source_file": "gfm_rag.pdf",
          "page": 3,
          "text": "16] enhances multi-hop retrieval by using a personalized PageRank algorithm to locate relevant knowledge with graphs. However, the graph structure can be noisy and incomplete, leading to suboptimal performance. Efforts to incorporate GNNs into graph-enhanced RAG [41, 18] have shown impressive results due to the multi-hop graph reasoning capabilities of GNNs in handling incomplete graphs [73]. Nonetheless, these methods still limit in generalizability due to the lack of a graph foundational model. Graph Foundation models (GFM) aims to be a large-scale model that can generalize to various datase",
          "citation": "(gfm_rag.pdf p3, chunk 2)"
        },
        {
          "evidence_id": "gfm_rag_p27_c001",
          "hybrid_score": 0.4356642385178442,
          "bm25_norm": 0.0,
          "dense_norm": 0.726107064196407,
          "source_file": "gfm_rag.pdf",
          "page": 27,
          "text": "Table 21: Comparison of the model performance under the KG-index constructed by different LLMs. Method HotpotQA MuSiQue 2Wiki R@2 R@5 R@2 R@5 R@2 R@5 GFM-RAG (gpt-4o-mini) 78.3 87.1 49.1 58.2 90.8 95.6 HippoRAG (gpt-4o-mini) 62.2 79.3 41.7 53.6 72.1 89.5 GFM-RAG (gpt-3.5-trubo) 75.6 84.7 46.1 55.8 85.2 90.4 HippoRAG (gpt-3.5-trubo) 60.5 77.7 40.9 51.9 70.7 89.1 of GFM-RAG is significantly higher than HippoRAG under both KG-indexes. This indicates that GFM-RAG is more robust to the quality of the KG-index, demonstrating the effectiveness of the GFM in graph reasoning and retrieval. F Prompts In",
          "citation": "(gfm_rag.pdf p27, chunk 1)"
        }
      ],
      "image_evidence": [
        {
          "evidence_id": "img_graphflow_rag_p04_architecture",
          "hybrid_score": 0.4468854021719025,
          "bm25_norm": 0.0,
          "dense_norm": 0.7448090036198375,
          "source_file": "graphflow_rag_p04_architecture.png",
          "page": 0,
          "text": "graphflow rag p04 architecture",
          "citation": "(image: graphflow_rag_p04_architecture.png)"
        },
        {
          "evidence_id": "img_graphflow_rag_p25_training_dynamics",
          "hybrid_score": 0.3494434394314893,
          "bm25_norm": 0.0,
          "dense_norm": 0.5824057323858155,
          "source_file": "graphflow_rag_p25_training_dynamics.png",
          "page": 0,
          "text": "graphflow rag p25 training dynamics",
          "citation": "(image: graphflow_rag_p25_training_dynamics.png)"
        }
      ],
      "missing_evidence_behavior": false,
      "support_gate_pass": true,
      "faithfulness_pass": true,
      "answer": "16] enhances multi-hop retrieval by using a personalized PageRank algorithm to locate relevant knowledge with graphs. However, the graph structure can be noisy and incomplete, leading to suboptimal performance. Efforts to incorporate GNNs into graph-enhanced RAG [41, 18] have shown impressive results due to the multi-hop graph reasoning capabilities of GNNs in handling incomplete graphs [73]. Nonetheless, these methods still limit in generalizability due to the lack of a graph foundational model. Graph Foundation models (GFM) aims to be a large-scale model that can generalize to various datase"
    }
  ]
}